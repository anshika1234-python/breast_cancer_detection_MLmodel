{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3359b7",
   "metadata": {},
   "source": [
    "# üß† Breast Cancer Detection Pipeline with Logistic Regression\n",
    "\n",
    "This notebook walks you through an end-to-end classical ML pipeline using logistic regression and feature importance, all based on scikit‚Äëlearn‚Äôs breast cancer dataset.\n",
    "\n",
    "**In this notebook you will:**\n",
    "1. Load & explore the data  \n",
    "2. Split into training/test sets  \n",
    "3. Scale features  \n",
    "4. Train logistic regression model  \n",
    "5. Evaluate performance  \n",
    "6. Analyze top predictive features  \n",
    "7. Save model artifacts  \n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# Cell 1: Imports & Data Loading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Quick info\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(\"Target distribution:\")\n",
    "print(y.value_counts().rename({0: 'malignant', 1: 'benign'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d6d59d",
   "metadata": {},
   "source": [
    "### What's in this dataset?\n",
    "\n",
    "- **569 samples**, each with **30 numeric features**\n",
    "- Binary target labels:  \n",
    "  - `0 = malignant` (cancerous)  \n",
    "  - `1 = benign` (non-cancerous)  \n",
    "- Features: measurements computed from cell nuclei\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c3c36e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 2: Exploratory Data Analysis (EDA)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m.concat([X, y.rename(\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m)], axis=\u001b[32m1\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Count of classes\u001b[39;00m\n\u001b[32m      5\u001b[39m plt.figure(figsize=(\u001b[32m4\u001b[39m,\u001b[32m4\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 2: Exploratory Data Analysis (EDA)\n",
    "df = pd.concat([X, y.rename('target')], axis=1)\n",
    "\n",
    "# Count of classes\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.countplot(x='target', data=df)\n",
    "plt.xticks([0,1], ['malignant', 'benign'])\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(df.corr(), cmap='coolwarm', fmt=\".2f\", square=True, linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e78eb16",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- The dataset is imbalanced (~63% benign, ~37% malignant).\n",
    "- Many features are correlated‚Äîeliminating redundancy may help the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f52e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Train/Test Split and Feature Scaling\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "print(\"X_train shape:\", X_train_s.shape, \"| X_test shape:\", X_test_s.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b7a9b4",
   "metadata": {},
   "source": [
    "**Why scale features?**  \n",
    "Logistic regression assumes all features contribute equally; scaling ensures they are on the same range, avoiding bias from large-magnitude features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd5aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Train Logistic Regression\n",
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "model.fit(X_train_s, y_train)\n",
    "\n",
    "# Save trained model\n",
    "joblib.dump(model, 'cancer_model.pkl')\n",
    "\n",
    "print(\"Model training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeb1c91",
   "metadata": {},
   "source": [
    "We use the `liblinear` solver since it‚Äôs effective for small to medium-sized datasets with binary targets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afefdf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Evaluate Model Performance\n",
    "y_pred = model.predict(X_test_s)\n",
    "\n",
    "print(\"‚úÖ Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=data.target_names,\n",
    "            yticklabels=data.target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7788150",
   "metadata": {},
   "source": [
    "- **Accuracy** tells us how many predictions were correct overall.\n",
    "- **Classification report** includes precision, recall, and F1-score‚Äîuseful for imbalanced data.\n",
    "- **Confusion matrix** visually breaks down true/false positives and negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7741e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Feature Importance Analysis\n",
    "r = permutation_importance(\n",
    "    model, X_test_s, y_test, n_repeats=10, random_state=42\n",
    ")\n",
    "importances = pd.Series(r.importances_mean, index=data.feature_names)\n",
    "top10 = importances.nlargest(10)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "top10.plot(kind='barh')\n",
    "plt.title(\"Top 10 Feature Importances (Permutation)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop features contributing to model decisions:\")\n",
    "for feat, score in top10.iteritems():\n",
    "    print(f\" ‚Ä¢ {feat}: importance score ‚âà {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b04ad",
   "metadata": {},
   "source": [
    "Permutation importance randomly shuffles each feature to see how it affects performance. The larger the drop in accuracy, the more important the feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b0a8c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèÅ Conclusion\n",
    "\n",
    "You have built a full machine learning pipeline for breast cancer detection:\n",
    "\n",
    "1. **Explored** data distribution and feature correlations  \n",
    "2. **Scaled** numeric features  \n",
    "3. **Trained** a logistic regression model  \n",
    "4. **Evaluated** model accuracy, precision, recall  \n",
    "5. **Interpreted** model behavior via feature importance  \n",
    "6. **Saved** models and scaler for future use  \n",
    "\n",
    "**Next steps you can try:**\n",
    "- Add **GridSearchCV** to tune regularization strength (`C`)  \n",
    "- Experiment with **other models** like Random Forest or SVM  \n",
    "- Visualize **ROC curve** and compute AUC  \n",
    "- Build a simple **Flask** or **Streamlit** app to serve predictions  \n",
    "---\n",
    "\n",
    "Make sure your `venv` is activated when you run this notebook. To get started:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "jupyter notebook\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
